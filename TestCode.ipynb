{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=F size=128x120 at 0x2AFB73FDBA8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sophie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2afb9c96160>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pgm2pil\n",
    "\n",
    "fname = 'datasets/faces/an2i/an2i_left_neutral_open.pgm'\n",
    "an2i = Path( fname )\n",
    "an2i.exists()\n",
    "\n",
    "import PIL.Image\n",
    "#origImageOpen = PIL.Image.open\n",
    "#PIL.Image.open = pgm2pil.imageOpenWrapper\n",
    "an2i_im = PIL.Image.open(fname)\n",
    "print(an2i_im)\n",
    "\n",
    "# or we can use the misc package that in turn uses PIL\n",
    "from scipy import misc\n",
    "an2i_im = misc.imread(fname)\n",
    "\n",
    "import importlib\n",
    "# importlib.reload(pgm2pil)\n",
    "\n",
    "\n",
    "# not needed anymore changed pgm2pil\n",
    "# import numpy as np\n",
    "# an2i_im_up = np.flipud(an2i_im)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make it non-blocking -- only needed once\n",
    "plt.ion() \n",
    "\n",
    "plt.imshow(an2i_im, cmap=plt.cm.gray)\n",
    "# Only needed if blocking\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "128\n",
      "[[ 49.03846   109.51923   117.69231   ...  60.48077    58.846153\n",
      "   60.48077  ]\n",
      " [ 39.23077    94.80769   101.34615   ...  62.115383   60.48077\n",
      "   60.48077  ]\n",
      " [ 34.326923   86.63461    91.53846   ...  62.115383   62.115383\n",
      "   62.115383 ]\n",
      " ...\n",
      " [  0.          0.          1.6346154 ...   0.          0.\n",
      "    0.       ]\n",
      " [  0.          0.          0.        ...   0.          0.\n",
      "    0.       ]\n",
      " [  0.          0.          0.        ...   0.          0.\n",
      "    0.       ]]\n"
     ]
    }
   ],
   "source": [
    "print(len(an2i_im))\n",
    "print(len(an2i_im[0]))\n",
    "print(an2i_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2 3 4]]\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# test append\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "print(a)\n",
    "a = a.reshape(1, -1)\n",
    "print(a)\n",
    "#a = np.empty((1,1))\n",
    "a = None\n",
    "\n",
    "for i in range(10):\n",
    "    #a = np.append(a, np.array([i]))\n",
    "    if a is None:\n",
    "        a = np.array([[i]])\n",
    "    else:\n",
    "        a = np.r_[a, np.array([[i]])]\n",
    "    \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try classic deep learning CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 4\n",
    "#epochs = 12\n",
    "epochs = 100\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 30, 32\n",
    "\n",
    "x_train = A4train\n",
    "x_test = A4test\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(Y4train_exp, num_classes)\n",
    "y_test = keras.utils.to_categorical(Y4test_exp, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train shape: (500, 30, 32, 1)\n",
    "500 train samples\n",
    "124 test samples\n",
    "Train on 500 samples, validate on 124 samples\n",
    "Epoch 1/100\n",
    "500/500 [==============================] - 3s 7ms/step - loss: 1.3920 - acc: 0.2420 - val_loss: 1.3891 - val_acc: 0.2419\n",
    "Epoch 2/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3854 - acc: 0.2620 - val_loss: 1.3882 - val_acc: 0.2419\n",
    "Epoch 3/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3865 - acc: 0.2420 - val_loss: 1.3888 - val_acc: 0.2097\n",
    "Epoch 4/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3857 - acc: 0.2320 - val_loss: 1.3913 - val_acc: 0.2177\n",
    "Epoch 5/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3847 - acc: 0.2520 - val_loss: 1.3895 - val_acc: 0.2097\n",
    "Epoch 6/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3835 - acc: 0.2640 - val_loss: 1.3891 - val_acc: 0.1855\n",
    "Epoch 7/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3804 - acc: 0.2920 - val_loss: 1.3887 - val_acc: 0.2177\n",
    "Epoch 8/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3827 - acc: 0.2720 - val_loss: 1.3908 - val_acc: 0.2742\n",
    "Epoch 9/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3825 - acc: 0.2840 - val_loss: 1.3889 - val_acc: 0.2500\n",
    "Epoch 10/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3800 - acc: 0.2880 - val_loss: 1.3880 - val_acc: 0.2097\n",
    "Epoch 11/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3767 - acc: 0.2600 - val_loss: 1.3946 - val_acc: 0.1774\n",
    "Epoch 12/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3733 - acc: 0.2860 - val_loss: 1.3971 - val_acc: 0.2097\n",
    "Epoch 13/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3735 - acc: 0.2920 - val_loss: 1.3912 - val_acc: 0.2419\n",
    "Epoch 14/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3770 - acc: 0.2940 - val_loss: 1.3942 - val_acc: 0.2016\n",
    "Epoch 15/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3703 - acc: 0.3120 - val_loss: 1.3959 - val_acc: 0.1855\n",
    "Epoch 16/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3675 - acc: 0.3220 - val_loss: 1.4006 - val_acc: 0.2419\n",
    "Epoch 17/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3610 - acc: 0.3300 - val_loss: 1.4048 - val_acc: 0.2177\n",
    "Epoch 18/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3713 - acc: 0.3140 - val_loss: 1.3991 - val_acc: 0.2016\n",
    "Epoch 19/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3595 - acc: 0.3200 - val_loss: 1.4025 - val_acc: 0.1935\n",
    "Epoch 20/100\n",
    "500/500 [==============================] - 2s 5ms/step - loss: 1.3657 - acc: 0.3120 - val_loss: 1.4056 - val_acc: 0.1855\n",
    "Epoch 21/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3597 - acc: 0.3060 - val_loss: 1.4053 - val_acc: 0.2016\n",
    "Epoch 22/100\n",
    "500/500 [==============================] - 3s 5ms/step - loss: 1.3535 - acc: 0.3080 - val_loss: 1.4154 - val_acc: 0.2258\n",
    "Epoch 23/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3532 - acc: 0.3260 - val_loss: 1.4082 - val_acc: 0.2419\n",
    "Epoch 24/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3494 - acc: 0.3280 - val_loss: 1.4054 - val_acc: 0.2419\n",
    "Epoch 25/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3583 - acc: 0.3220 - val_loss: 1.4148 - val_acc: 0.2258\n",
    "Epoch 26/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3401 - acc: 0.3500 - val_loss: 1.4217 - val_acc: 0.2339\n",
    "Epoch 27/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3340 - acc: 0.3400 - val_loss: 1.4160 - val_acc: 0.2419\n",
    "Epoch 28/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3326 - acc: 0.3480 - val_loss: 1.4360 - val_acc: 0.2016\n",
    "Epoch 29/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3268 - acc: 0.3520 - val_loss: 1.4344 - val_acc: 0.2419\n",
    "Epoch 30/100\n",
    "500/500 [==============================] - 2s 5ms/step - loss: 1.3474 - acc: 0.3180 - val_loss: 1.4263 - val_acc: 0.2258\n",
    "Epoch 31/100\n",
    "500/500 [==============================] - 2s 5ms/step - loss: 1.3154 - acc: 0.3800 - val_loss: 1.4359 - val_acc: 0.2258\n",
    "Epoch 32/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3133 - acc: 0.3720 - val_loss: 1.5198 - val_acc: 0.2097\n",
    "Epoch 33/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3605 - acc: 0.3300 - val_loss: 1.4283 - val_acc: 0.2339\n",
    "Epoch 34/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3301 - acc: 0.3300 - val_loss: 1.4441 - val_acc: 0.1613\n",
    "Epoch 35/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3231 - acc: 0.3560 - val_loss: 1.4411 - val_acc: 0.2177\n",
    "Epoch 36/100\n",
    "500/500 [==============================] - 2s 5ms/step - loss: 1.2935 - acc: 0.3940 - val_loss: 1.4507 - val_acc: 0.2016\n",
    "Epoch 37/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2914 - acc: 0.4000 - val_loss: 1.4675 - val_acc: 0.2097\n",
    "Epoch 38/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2791 - acc: 0.3960 - val_loss: 1.4852 - val_acc: 0.2097\n",
    "Epoch 39/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2871 - acc: 0.3820 - val_loss: 1.4858 - val_acc: 0.1935\n",
    "Epoch 40/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2466 - acc: 0.4340 - val_loss: 1.5500 - val_acc: 0.2016\n",
    "Epoch 41/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2806 - acc: 0.4120 - val_loss: 1.4851 - val_acc: 0.1935\n",
    "Epoch 42/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.3004 - acc: 0.3740 - val_loss: 1.4594 - val_acc: 0.1855\n",
    "Epoch 43/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2647 - acc: 0.4200 - val_loss: 1.4975 - val_acc: 0.1855\n",
    "Epoch 44/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2492 - acc: 0.4020 - val_loss: 1.4978 - val_acc: 0.2016\n",
    "Epoch 45/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2653 - acc: 0.3900 - val_loss: 1.5163 - val_acc: 0.1613\n",
    "Epoch 46/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2202 - acc: 0.4260 - val_loss: 1.5324 - val_acc: 0.2016\n",
    "Epoch 47/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2094 - acc: 0.4340 - val_loss: 1.5534 - val_acc: 0.2177\n",
    "Epoch 48/100\n",
    "500/500 [==============================] - 2s 5ms/step - loss: 1.2128 - acc: 0.4280 - val_loss: 1.5669 - val_acc: 0.1613\n",
    "Epoch 49/100\n",
    "500/500 [==============================] - 3s 5ms/step - loss: 1.2047 - acc: 0.4300 - val_loss: 1.5748 - val_acc: 0.1694\n",
    "Epoch 50/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2145 - acc: 0.4540 - val_loss: 1.5661 - val_acc: 0.1532\n",
    "Epoch 51/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1982 - acc: 0.4520 - val_loss: 1.5033 - val_acc: 0.1452\n",
    "Epoch 52/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1889 - acc: 0.4520 - val_loss: 1.6610 - val_acc: 0.1774\n",
    "Epoch 53/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.2179 - acc: 0.4200 - val_loss: 1.5823 - val_acc: 0.1774\n",
    "Epoch 54/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1385 - acc: 0.4740 - val_loss: 1.6281 - val_acc: 0.2097\n",
    "Epoch 55/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1340 - acc: 0.4840 - val_loss: 1.7046 - val_acc: 0.1613\n",
    "Epoch 56/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1836 - acc: 0.4600 - val_loss: 1.6487 - val_acc: 0.2258\n",
    "Epoch 57/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1454 - acc: 0.4820 - val_loss: 1.6877 - val_acc: 0.1532\n",
    "Epoch 58/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1352 - acc: 0.4500 - val_loss: 1.6759 - val_acc: 0.1694\n",
    "Epoch 59/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1093 - acc: 0.4980 - val_loss: 1.7080 - val_acc: 0.1935\n",
    "Epoch 60/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.0924 - acc: 0.5200 - val_loss: 1.6946 - val_acc: 0.1855\n",
    "Epoch 61/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1612 - acc: 0.4380 - val_loss: 1.5613 - val_acc: 0.2016\n",
    "Epoch 62/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1159 - acc: 0.5120 - val_loss: 1.6431 - val_acc: 0.1290\n",
    "Epoch 63/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.0872 - acc: 0.5420 - val_loss: 1.7162 - val_acc: 0.2016\n",
    "Epoch 64/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.1134 - acc: 0.4940 - val_loss: 1.6771 - val_acc: 0.1774\n",
    "Epoch 65/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.0151 - acc: 0.5440 - val_loss: 1.7358 - val_acc: 0.1694\n",
    "Epoch 66/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.0525 - acc: 0.5160 - val_loss: 1.7982 - val_acc: 0.1774\n",
    "Epoch 67/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.0185 - acc: 0.5360 - val_loss: 1.8347 - val_acc: 0.1855\n",
    "Epoch 68/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.0000 - acc: 0.5240 - val_loss: 1.8077 - val_acc: 0.1694\n",
    "Epoch 69/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.9610 - acc: 0.5580 - val_loss: 1.8220 - val_acc: 0.1694\n",
    "Epoch 70/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 1.0040 - acc: 0.5580 - val_loss: 1.7513 - val_acc: 0.1613\n",
    "Epoch 71/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.9400 - acc: 0.6000 - val_loss: 1.8427 - val_acc: 0.1935\n",
    "Epoch 72/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.9839 - acc: 0.5360 - val_loss: 1.7965 - val_acc: 0.1935\n",
    "Epoch 73/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.9475 - acc: 0.5840 - val_loss: 1.8910 - val_acc: 0.2177\n",
    "Epoch 74/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.9484 - acc: 0.5960 - val_loss: 1.8322 - val_acc: 0.1694\n",
    "Epoch 75/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.9773 - acc: 0.5860 - val_loss: 1.7348 - val_acc: 0.2177\n",
    "Epoch 76/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8939 - acc: 0.6160 - val_loss: 1.9865 - val_acc: 0.1935\n",
    "Epoch 77/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8791 - acc: 0.6000 - val_loss: 1.9631 - val_acc: 0.1855\n",
    "Epoch 78/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8447 - acc: 0.6340 - val_loss: 2.0111 - val_acc: 0.1855\n",
    "Epoch 79/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.9384 - acc: 0.6000 - val_loss: 1.9289 - val_acc: 0.1694\n",
    "Epoch 80/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8468 - acc: 0.6560 - val_loss: 2.0707 - val_acc: 0.1774\n",
    "Epoch 81/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8992 - acc: 0.6000 - val_loss: 1.8449 - val_acc: 0.1694\n",
    "Epoch 82/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8866 - acc: 0.6380 - val_loss: 1.8270 - val_acc: 0.1935\n",
    "Epoch 83/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8641 - acc: 0.6400 - val_loss: 1.8494 - val_acc: 0.1855\n",
    "Epoch 84/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8129 - acc: 0.6800 - val_loss: 2.1821 - val_acc: 0.1855\n",
    "Epoch 85/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8621 - acc: 0.6260 - val_loss: 2.0576 - val_acc: 0.1613\n",
    "Epoch 86/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7507 - acc: 0.7040 - val_loss: 2.1574 - val_acc: 0.1935\n",
    "Epoch 87/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8207 - acc: 0.6120 - val_loss: 2.0007 - val_acc: 0.1694\n",
    "Epoch 88/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7314 - acc: 0.6920 - val_loss: 2.3422 - val_acc: 0.1774\n",
    "Epoch 89/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.8428 - acc: 0.6240 - val_loss: 2.2303 - val_acc: 0.1774\n",
    "Epoch 90/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7273 - acc: 0.6760 - val_loss: 2.3137 - val_acc: 0.1855\n",
    "Epoch 91/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7333 - acc: 0.7020 - val_loss: 2.4261 - val_acc: 0.1855\n",
    "Epoch 92/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7727 - acc: 0.6480 - val_loss: 2.2870 - val_acc: 0.1855\n",
    "Epoch 93/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7231 - acc: 0.6900 - val_loss: 2.3196 - val_acc: 0.1855\n",
    "Epoch 94/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7265 - acc: 0.6680 - val_loss: 2.2803 - val_acc: 0.1855\n",
    "Epoch 95/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7171 - acc: 0.6900 - val_loss: 2.4446 - val_acc: 0.1855\n",
    "Epoch 96/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.6958 - acc: 0.7060 - val_loss: 2.4727 - val_acc: 0.1935\n",
    "Epoch 97/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7312 - acc: 0.7140 - val_loss: 2.1416 - val_acc: 0.2097\n",
    "Epoch 98/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.6669 - acc: 0.7280 - val_loss: 2.4743 - val_acc: 0.2016\n",
    "Epoch 99/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.7140 - acc: 0.6840 - val_loss: 2.3721 - val_acc: 0.2097\n",
    "Epoch 100/100\n",
    "500/500 [==============================] - 2s 4ms/step - loss: 0.6553 - acc: 0.7240 - val_loss: 2.3532 - val_acc: 0.1855\n",
    "Test loss: 2.3531548746170534\n",
    "Test accuracy: 0.18548387168876587"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
